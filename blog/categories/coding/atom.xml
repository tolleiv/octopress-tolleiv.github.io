<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Coding | blog.tolleiv.de]]></title>
  <link href="http://blog.tolleiv.de/blog/categories/coding/atom.xml" rel="self"/>
  <link href="http://blog.tolleiv.de/"/>
  <updated>2015-11-20T18:24:20+01:00</updated>
  <id>http://blog.tolleiv.de/</id>
  <author>
    <name><![CDATA[Tolleiv Nietsch]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using genetic algorithms to optimize Apache Solr boost factors.]]></title>
    <link href="http://blog.tolleiv.de/2013/06/genetic-algorithms-boosting-solr/"/>
    <updated>2013-06-06T20:47:56+02:00</updated>
    <id>http://blog.tolleiv.de/2013/06/genetic-algorithms-boosting-solr</id>
    <content type="html"><![CDATA[<p><a href="/uploads/2013/06/Bildschirmfoto-2013-05-29-um-18.08.18.png"><img src="/uploads/2013/06/Bildschirmfoto-2013-05-29-um-18.08.18-150x150.png" alt="Configuration interface." /></a> Configuration interface.One thing I took along from last year&rsquo;s ApacheCon was the idea to combine Apache Solr along with some mathematical search algorithms to figure out boost factor values. I did some work on that back then and on the way to this year&rsquo;s BerlinBuzzwords. Now I finally have a proof-of-concept working which I&rsquo;d like to share. If you want to have a look right away &ndash; the code can be found on <a href="http://github.com/tolleiv/boostgenetics">Github</a>.</p>

<h2>The problem to solve:</h2>

<p>When running search indexes with Solr, one thing you might stumble opon is that you&rsquo;ve various fields in your documents and you&rsquo;ve to adjust their weights to get reasonable results. Finding those &ldquo;boosting&rdquo; values can be quite complex when you have many fields and many scenarios. Usually getting the values right is a task for very experienced integrators.</p>

<p>``` bash
   /solr/select?defType=dismax&amp;q=my+query</p>

<pre><code> &amp;qf=title^**42**+description^**23**+footnotes^**5**+dalmatiners^**101**+foo^**9001**+comments
</code></pre>

<p>```</p>

<p>Looking at it from a more technical perspective &ndash; when your Solr query looks like the one above, the question you&rsquo;ve to answer is how the values for the highlighted numbers should look like to get <em>reasonable</em> results.</p>

<h2>Measuring &ldquo;reasonable&rdquo;:</h2>

<p>In order to solve the problem, the first thing we&rsquo;ve to do, is to answer what we expect the outcome to look like. In other words, we&rsquo;ve to measure how reasonable a specific solution is. For a search engine this can be done with some sample queries and some expectations along with that. The expectation could come in a form that we explicitly tell which documents we expect in the result lists of specific queries (and at predefined positions). Once we&rsquo;ve these expectations, we can simple test agains the expectations and check whether or not specific boost factor values actually satisfy them.</p>

<p>A small example on that: In case we&rsquo;ve a sample query with the expectation that document 123 appears in the first position and document 248 appears second. We could run this with two specific boost factor combinations (a) and (b). Along with (a) we might find that, document 123 actually ranks on position 8 and document 248 is found on position 4 and with (b) we&rsquo;d find them on pos. 2 and pos. 14 &ndash; which one would we consider to be better?
Comparing the &ldquo;error&rdquo; and &ldquo;squared error&rdquo; produced by (a) and (b) gives us a possible hint:</p>

<ul>
<li>(a): 8-1 + 4-2 = 7+2 = 9</li>
<li>(8-1)² + (4-2)² = 49+4 = 53</li>
<li>(b): 2-1 + 14-2 = 1+12 = 13</li>
<li>(2-1)² + (14-2)² = 1+144 = 145</li>
</ul>


<p>While it&rsquo;s not clear to compare both with just the normal error value comparision, the squared error shows clearly that (a) seems to outperform (b) in those cases and we should choose (a) for further considerations.</p>

<p>Being able to determine the &ldquo;error&rdquo; introduced by a specific solution then enables us to compare various solutions and helps us to play around with all sorts of optimizations.</p>

<h2>The idea:</h2>

<p>With a defined &ldquo;cost function&rdquo; like the one I introduced before, you&rsquo;d be able to tackle the problem with some well known algorithmic solutions. Considering the boost factors to be represented as numerical vectors, we could use gradient methodologies to find good solutions. But having 20-40 fields per document would require to &ldquo;search&rdquo; a large numerical space and with gradient methods, this would result in a large amount of queries.</p>

<p>Another approach to run these optimizations, is to utilize genetic algorithms which kind of help to find good solutions within predictable amounts of time. You might know genetic algorithms for some lectures where people solved <a href="http://www.math.hmc.edu/seniorthesis/archives/2001/kbryant/kbryant-2001-thesis.pdf">traveling salesman problems</a> and actually the only change you&rsquo;d have to make is to exchange the traveling salesman cost function with the cost function you saw before and you&rsquo;d be close to a solution already.</p>

<p><strong>With some more details:</strong> Genetic algorithms take an amount of randomly generated possible solutions (called the <em>population</em>) and try to find good solutions by applying the typical methods you know from your biology class (mutations, crossovers, natural selection). <em>Natural selection</em> is done in a way that from each generation only the top 50% &ldquo;survive and the rest of the population is filled up with now solutions generated through <em>mutations</em> (random parameter changes of existing solutions) and <em>crossovers</em> (interchanging parts of two existing solutions to create a third one). All solutions are always measured and compared on their response to the defined cost function and this way we&rsquo;re always able to determine the "best known solution&rdquo; even after very short time.</p>

<p>If that sounds too high-level. For the shown query from above, the vector [42,23,5,101,9001,1] is the vector I used. In addition let&rsquo;s considering we have another vector [1,1,1,1,1,1] with equal weights for all fields. Assuming those are our fittest vectors at a given time, we could derive new possible solutions by mutating them (e.g. [42,23,5,101,9001,1] ~> [42,23,5,101,505,1] ) or creating a cross-over between both ( [42,23,5,101,9001,1] &amp; [1,1,1,1,1,1] ~> [42,23,5,1,1,1]). Even adding new random vectors to our population might add some value. Once we found enough new vectors to have a population of a decent size, we&rsquo;d compare the fitness and keep only the top 50% and continue our process until we reach convergence or a fixed iteration limit.</p>

<p>A drawback of the genetic algorithm is that it might not deliver the optimal result, because it never found it. But that&rsquo;s just how nature works too. So it&rsquo;s more that you&rsquo;ve to sacrifice &ldquo;training runtime&rdquo; over accuracy or vice versa.</p>

<h2>Implementation:</h2>

<p><a href="/uploads/2013/06/Bildschirmfoto-2013-05-29-um-18.10.43.png"><img src="/uploads/2013/06/Bildschirmfoto-2013-05-29-um-18.10.43-150x150.png" alt="10 generation optimization" /></a> 10 generation optimizationThere&rsquo;s really not too much to say other than that the code can be found in <a href="http://github.com/tolleiv/boostgenetics">Github</a>. I used NodeJS with ExpressJs, SocketIO and an Twitter Bootstrap interface to have a relatively good looking and somewhat performing proof-of-concept. I used that setup, because NodeJS seems to me as the most easiest way to talk to Solr and it &ldquo;promises&rdquo; to be performant even with larger examples. SocketIO helped a lot to ease the pain when it comes to Server &lt;> Client communication. The only drawback of that setup is the that everything had to be turned into something which is able to deal with asynchronous processing. This makes the algorithmic parts look a bit odd and bloated &ndash; but for me the benefits outweigh the odds.</p>

<h2>Final thoughts:</h2>

<p>The proof-of-concept, which you&rsquo;ll find on the Github repository, demonstrates that such type of optimization can work and that&rsquo;s more or less all I wanted to do with it.</p>

<p>You can use the NodeJS tool with any of your Solr indexes and just go ahead and try it yourself. There are many parts which aren&rsquo;t too accurate yet, especially the measuring could maybe done better with precision and recall measurements &ndash; but I assume that any type of cost function would work for now, that&rsquo;s why P/R wasn&rsquo;t implemented along with the tool. Also I&rsquo;m not a NodeJS expert and the code might not follow best practice atm. &ndash; I&rsquo;d be very happy to change that if anyone is interested to help?</p>

<hr />

<p>When I did a small presentation during the <a href="http://berlinbuzzwords.de/wiki/barcamp">Berlin Buzzwords bar camp</a> I also got some other questions which don&rsquo;t necessarily relate to just this implementation but to all sorts of automated optimizations.</p>

<p><em>The first question was, how to get the list of example queries and the &ldquo;expected&rdquo; documents for them.</em> For now I assume that most applications at least know their top 50 or top 100 search and they should be able to predefine &ldquo;relevant&rdquo; documents for those searches. That&rsquo;s at least what I assume everyone should have. Another way to generate the test data is to do some log file analyses and check the search and pick/weight the documents people clicked from within the results. This should also help to get some results.</p>

<p><em>Another questions related to that was wether long tail would fall behind with that approach.</em> As this is only a proof-of-concept, I wasn&rsquo;t really able to answer this. But I assume that long-tail searches would still benefit a lot more from the relevance certain documents gain due to high TF-IDF scores and those should then outweigh the &ldquo;scoring bias&rdquo; in a way. Another approach (known from machine learning) could be to leave out the top 1% of the documents (and searches) and just optimize for the rest of the top X% and afterwards check wether the top 1% still performs good &ndash; this way long tail could be &ldquo;protected a bit more.</p>

<p><em>And the last question was whether I tested other (gradient based) algorithms already.</em> The answer was and is, no. So far this only ran on my MacBook and I really didn&rsquo;t want to benchmark my CPU. The code itself is somewhat prepared to take other optimization methods but I didn&rsquo;t add in others. If you&rsquo;re interested to do so &ndash; I&rsquo;d be happy to accept your pull-requests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Signal / Slots in Extbase]]></title>
    <link href="http://blog.tolleiv.de/2011/11/signal-slots-in-extbase/"/>
    <updated>2011-11-30T18:17:02+01:00</updated>
    <id>http://blog.tolleiv.de/2011/11/signal-slots-in-extbase</id>
    <content type="html"><![CDATA[<p>A nice thing to have at hand is definately <a href="http://en.wikipedia.org/wiki/Signals_and_slots">Signal and Slots</a>. I heard <a href="http://f.oer.tel">Felix</a> talking about them quite often and I finally found a nice usecase and came to play with them a little bit this afternoon. And just to avoid that others have to look around too much to find how they can get them to work here&rsquo;s how it&rsquo;s working for me.</p>

<p>First of all you should understand the concept. This nice little &ldquo;definition&rdquo; (from <a href="http://flow3.typo3.org/documentation/guide/partiii/signalsandslots.html">flow3.typo3.org</a>) sums it up pretty well:</p>

<blockquote><p>A signal, which contains event information as it makes sense in the case at hand, can be emitted (sent) by any part of the code and is received by one or more slots, which can be any function<del> in FLOW3</del> in extbase.</p></blockquote>

<p>To get this running in extbase, you&rsquo;ve to get hold of the <em>Tx_Extbase_SignalSlot_Dispatcher</em>, which is the central instance to manage all of it. Within Extbase that&rsquo;s done easily with this snippet within your classes:</p>

<pre><code>   ...
    /**
     * @var Tx_Extbase_SignalSlot_Dispatcher
     */
    protected $signalSlotDispatcher;

    /**
     * @param Tx_Extbase_SignalSlot_Dispatcher $signalSlotDispatcher
     */
    public function injectSignalSlotDispatcher(Tx_Extbase_SignalSlot_Dispatcher $signalSlotDispatcher) {
        $this-&gt;signalSlotDispatcher = $signalSlotDispatcher;
    }
   ...
</code></pre>

<p>Next thing is to make use of it. The Slot (listener) part could look like one of following blocks. In all cases you define the Signal by it&rsquo;s class (not necessarily a PHP Class) and it&rsquo;s name. Next to that the Slot can either be defined by a Closure, an object with a method name or a PHP-Class and a method name.</p>

<pre><code>   ...
// Using a closure
$this-&gt;signalSlotDispatcher-&gt;connect(
      'Crunching', 'emitDataReady', function($data) { crunch($data) }, NULL, FALSE
);
   ...
// Using a method of the current object
$this-&gt;signalSlotDispatcher-&gt;connect(
     'Crunching', 'emitDataReady', $this, 'crunch', FALSE
);
   ...
// Using a method of the specified class
$this-&gt;signalSlotDispatcher-&gt;connect(
     'Crunching', 'emitDataReady', 'Cruncher', 'crunch', FALSE
);
   ...
</code></pre>

<p>To trigger the Signal which invokes the Slots registered above, you&rsquo;ve to run the following code.</p>

<pre><code>$this-&gt;signalSlotDispatcher-&gt;dispatch('Crunching', 'emitDataReady', array($data));
</code></pre>

<p>One thing I found was that by default the <em>Tx_Extbase_SignalSlot_Dispatcher</em> it not a Singleton in older extbase versions. Bastian fixed that already in the <a href="https://review.typo3.org/#change,6785">master</a> and <a href="https://review.typo3.org/#change,6786">1-4</a> branches and lucky enough this change was part within the TYPO3 4.6.1 release. But I think it&rsquo;s still important to mention that this wasn&rsquo;t the default from the beginning on.</p>

<p>Even if <a href="http://flow3.typo3.org/documentation/guide/partiii/signalsandslots.html">AOP is a nicer way to implement this feature</a>, the extbase backport still works pretty straigh forward.</p>

<p>Edit: One thing I&rsquo;ve to add &ndash; Felix is not &ldquo;just&rdquo; talking about Signal/Slots &ndash; he&rsquo;s the one to thank for the <a href="https://review.typo3.org/1563">backport</a>. And now that his <a href="http://blog.foertel.com/2011/10/using-signalslots-in-extbase/">blog</a> is running again &ndash; this post seems like a summary ;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[imagemap_wizard 0.5.3]]></title>
    <link href="http://blog.tolleiv.de/2009/10/imagemap_wizard-0-5-3/"/>
    <updated>2009-10-22T21:18:39+02:00</updated>
    <id>http://blog.tolleiv.de/2009/10/imagemap_wizard-0-5-3</id>
    <content type="html"><![CDATA[<p>Last Sunday I&rsquo;ve released the first official stable version of my <a href="http://blog.tolleiv.de/2009/07/typo3-extensions/">imagemap_wizard</a> extension <a href="http://typo3.org/extensions/repository/view/imagemap_wizard/current/">(TER</a>).
I though that&rsquo;s a good moment to review the introduction text on the project-homepage and that&rsquo;s how it looks like &ndash; <a href="http://forge.typo3.org/projects/show/extension-imagemap_wizard">forge.typo3.org/projects/show/extension-imagemap_wizard</a></p>

<p>Especially due to the missing/broken TER download counter I&rsquo;m still not sure whether the work was worth it. I hope some marketing and the given information about all the cool featutes is enough for newbees and TYPO3 pro&rsquo;s. to  switch over to this extension ;)</p>

<p>The 0.6 releases will focus on some UI and usability improvements and looking at my old overall schedule for the 1.0 release there&rsquo;s &ldquo;only&rdquo; one big feature missing &ndash; the integration into regular content elements (e.g. &ldquo;text w/image&rdquo;).  So stay tuned :D</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[multiple arguments for mocked functions....]]></title>
    <link href="http://blog.tolleiv.de/2009/08/multiple-arguments-for-mocked-functions/"/>
    <updated>2009-08-17T23:38:45+02:00</updated>
    <id>http://blog.tolleiv.de/2009/08/multiple-arguments-for-mocked-functions</id>
    <content type="html"><![CDATA[<p>If you look into the PHPUnit documentation (<a href="http://www.phpunit.de/manual/3.3/en/test-doubles.html#test-doubles.mock-objects"> http://www.phpunit.de/manual/3.3/en/test-doubles.html#test-doubles.mock-objects</a> ) you&rsquo;ll see some nice examples but non of them shows how to translate a function with multiple arguments into a mock-assumption.</p>

<p>Within the examples you&rsquo;ll find:
<code>$observer-&gt;expects($this-&gt;once())-&gt;method('update')  
-&gt;with($this-&gt;equalTo('something'));
</code></p>

<p>So what if the &ldquo;update&rdquo; function has two arguments, pretty easy:
<code>$observer-&gt;expects($this-&gt;once())-&gt;method('update')  
-&gt;with($this-&gt;equalTo('something'), $this-&gt;equalTo('something else'));
</code></p>

<p>I guess Sebastian though that that there&rsquo;s no need for documentation if something is so obvious :(</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[www.encodechain.com]]></title>
    <link href="http://blog.tolleiv.de/2009/08/www-encodechain-com/"/>
    <updated>2009-08-08T14:54:13+02:00</updated>
    <id>http://blog.tolleiv.de/2009/08/www-encodechain-com</id>
    <content type="html"><![CDATA[<p><a href="/uploads/2009/08/encodingchain-0.1.png"><img src="/uploads/2009/08/encodingchain-0.1-300x221.png" alt="encodingchain-0.1" /></a>I just &ldquo;released&rdquo; <a href="http://www.encodechain.com">encodechain.com</a>. A little tool which enables to combine various popular PHP conversion methods and to check how they affect your input&hellip; feel free to give me some feedback :)</p>

<p>I&rsquo;m also not sure whether I choose the right name for it &hellip; O_o</p>
]]></content>
  </entry>
  
</feed>
